{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbd58e4-9d23-4463-9505-b00eeaa6694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "from tqdm import TqdmWarning\n",
    "    \n",
    "warnings.filterwarnings(module=\"tqdm.auto\", action=\"ignore\", category=TqdmWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0977d55c-e4b8-4bd9-898e-e190acd2ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation.loader import load\n",
    "from segmentation.model import ResnetCrackModel, CaptumModel\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6dc641-e15f-4f7f-b304-a6b1a19ca5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "data = load(\"3\", transform=transform, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576b2b19-2733-4691-a4b4-9fb885ecb740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 211/211 [01:03<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Average Batch Loss: 0.23228935410061155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Validation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:08<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Val Accuracy: 0.93\n",
      "Epoch 1/100 Average Batch Loss: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 211/211 [01:03<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Average Batch Loss: 0.2114237799039949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: Validation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:08<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Val Accuracy: 0.94\n",
      "Epoch 2/100 Average Batch Loss: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 211/211 [01:06<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Average Batch Loss: 0.19901510606568432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: Validation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:10<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Val Accuracy: 0.92\n",
      "Epoch 3/100 Average Batch Loss: 0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 211/211 [01:07<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Average Batch Loss: 0.18354525808598052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: Validation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 91/91 [00:10<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Val Accuracy: 0.94\n",
      "Epoch 4/100 Average Batch Loss: 0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: Training: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 211/211 [01:07<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Average Batch Loss: 0.18230898867656975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: Validation:  35%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 32/91 [00:03<00:07,  8.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m21\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m ResnetCrackModel(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m18\u001b[39m\u001b[38;5;124m\"\u001b[39m, reuse_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# model = ResnetCrackModel(version=\"18\", path=\"kek.pth\")\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/segmentation/segmentation/model.py:76\u001b[0m, in \u001b[0;36mCrackModel.train\u001b[0;34m(self, train_loader, val_loader, epochs, best_model, val_acc_threshold, stagnation_threshold)\u001b[0m\n\u001b[1;32m     74\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 76\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: Validation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_correct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_total\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_val_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurrent_loss\u001b[49m\n",
      "File \u001b[0;32m~/repos/segmentation/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/repos/segmentation/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/repos/segmentation/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/repos/segmentation/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/segmentation/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/segmentation/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/segmentation/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/repos/segmentation/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.manual_seed(21)\n",
    "\n",
    "model = ResnetCrackModel(version=\"18\", reuse_weights=False)\n",
    "model.train(data.train_loader, data.val_loader, epochs=100)\n",
    "\n",
    "# model = ResnetCrackModel(version=\"18\", path=\"kek.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87cf29cf-9d26-46da-9458-04a42d6b95f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53/53 [00:13<00:00,  3.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0663, device='cuda:0'), 0.9817109144542773)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.evaluate(data.test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7b5e20-cdb0-46b2-8368-4f94ed8e8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CaptumModel(model.model, 99.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e843c-dd89-4073-8fab-a377c5c4fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                    | 0/1695 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                                                                                                                                           | 1/1695 [00:01<50:05,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                                                                                                           | 2/1695 [00:03<54:06,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                                                                                                                                           | 3/1695 [00:05<56:02,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                                                                                                                                           | 4/1695 [00:07<56:20,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▋                                                                                                                                                                                                                                         | 5/1695 [00:10<1:06:26,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▊                                                                                                                                                                                                                                         | 6/1695 [00:13<1:10:43,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▉                                                                                                                                                                                                                                         | 7/1695 [00:15<1:05:13,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|█                                                                                                                                                                                                                                         | 8/1695 [00:17<1:03:10,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                                                                                                                                                        | 9/1695 [00:19<1:01:22,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▍                                                                                                                                                                                                                                         | 10/1695 [00:21<58:27,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▌                                                                                                                                                                                                                                         | 11/1695 [00:23<54:58,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▋                                                                                                                                                                                                                                         | 12/1695 [00:24<51:58,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▊                                                                                                                                                                                                                                         | 13/1695 [00:26<48:29,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▉                                                                                                                                                                                                                                         | 14/1695 [00:27<46:07,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██                                                                                                                                                                                                                                         | 15/1695 [00:29<44:28,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▏                                                                                                                                                                                                                                        | 16/1695 [00:30<42:44,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▎                                                                                                                                                                                                                                        | 17/1695 [00:32<41:47,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▍                                                                                                                                                                                                                                        | 18/1695 [00:33<41:43,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▋                                                                                                                                                                                                                                        | 19/1695 [00:34<39:34,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▊                                                                                                                                                                                                                                        | 20/1695 [00:36<39:59,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██▉                                                                                                                                                                                                                                        | 21/1695 [00:37<40:28,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███                                                                                                                                                                                                                                        | 22/1695 [00:39<39:58,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███▏                                                                                                                                                                                                                                       | 23/1695 [00:40<40:23,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███▎                                                                                                                                                                                                                                       | 24/1695 [00:42<40:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|███▍                                                                                                                                                                                                                                       | 25/1695 [00:43<40:09,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▌                                                                                                                                                                                                                                       | 26/1695 [00:44<40:28,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▋                                                                                                                                                                                                                                       | 27/1695 [00:46<40:36,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▉                                                                                                                                                                                                                                       | 28/1695 [00:47<39:53,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████                                                                                                                                                                                                                                       | 29/1695 [00:49<39:41,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▏                                                                                                                                                                                                                                      | 30/1695 [00:51<44:01,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▎                                                                                                                                                                                                                                      | 31/1695 [00:53<47:20,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▍                                                                                                                                                                                                                                      | 32/1695 [00:54<45:36,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▌                                                                                                                                                                                                                                      | 33/1695 [00:56<45:06,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▋                                                                                                                                                                                                                                      | 34/1695 [00:57<43:45,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▊                                                                                                                                                                                                                                      | 35/1695 [00:59<42:47,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|████▉                                                                                                                                                                                                                                      | 36/1695 [01:00<42:37,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▏                                                                                                                                                                                                                                     | 37/1695 [01:02<46:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▏                                                                                                                                                                                                                                   | 38/1695 [01:06<1:00:12,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▎                                                                                                                                                                                                                                   | 39/1695 [01:08<1:01:03,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▌                                                                                                                                                                                                                                     | 40/1695 [01:09<55:48,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▋                                                                                                                                                                                                                                     | 41/1695 [01:11<51:33,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█████▊                                                                                                                                                                                                                                     | 42/1695 [01:13<49:53,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████▉                                                                                                                                                                                                                                     | 43/1695 [01:14<47:38,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██████                                                                                                                                                                                                                                     | 44/1695 [01:16<45:49,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██████▏                                                                                                                                                                                                                                    | 45/1695 [01:17<46:40,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██████▍                                                                                                                                                                                                                                    | 46/1695 [01:20<51:23,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██████▌                                                                                                                                                                                                                                    | 47/1695 [01:22<51:58,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██████▋                                                                                                                                                                                                                                    | 48/1695 [01:23<50:01,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitmaps resized shape (448, 448, 224)\n",
      "inputs shape torch.Size([1, 3, 224, 224])\n",
      "classes of interest shape (all ones) torch.Size([1])\n",
      "heatmaps shape (3, 224, 224)\n",
      "heatmaps transformed shape (3, 224, 224)\n",
      "bitmaps shape (3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "for i in ct(DataLoader(data.test_dataset, batch_size=1)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23f79aa-a7d6-4842-ae16-0200e508f698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
